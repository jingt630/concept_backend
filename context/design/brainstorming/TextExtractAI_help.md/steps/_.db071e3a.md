---
timestamp: 'Sun Oct 19 2025 20:04:08 GMT-0400 (Eastern Daylight Time)'
parent: '[[..\20251019_200408.5f60e1e2.md]]'
content_id: db071e3a09925b9dcc69a4a08bc3e5819bfb53a66eab4efe16515907e6dfd0c2
---

# prompt explain how AI file get the prompt from .md files and how I can modify it such that it reads the prompt as one part and

accept image like in the following code and push it to the parts list.

async executeLLM (prompt: string, imagePath?: string): Promise<string> {
try {
// Initialize Gemini AI
const genAI = new GoogleGenerativeAI(this.apiKey);
const model = genAI.getGenerativeModel({
model: "gemini-2.5-flash-lite",
generationConfig: {
maxOutputTokens: 1000,
}
});
const parts: any\[] = \[{ text: prompt }];

```
        if (imagePath) {
        const imageData = fs.readFileSync(imagePath);
        parts.push({
            inlineData: {
            data: imageData.toString("base64"),
            mimeType: "image/png",
            },
        });
        }

        // Execute the LLM
        const result = await model.generateContent(parts);
        const response = await result.response;
        const text = response.text();
        return text;
    } catch (error) {
        console.error('‚ùå Error calling Gemini API:', (error as Error).message);
        throw error;
    }    }
```
