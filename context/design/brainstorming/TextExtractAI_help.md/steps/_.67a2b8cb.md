---
timestamp: 'Sun Oct 19 2025 20:04:49 GMT-0400 (Eastern Daylight Time)'
parent: '[[..\20251019_200449.27eb89ff.md]]'
content_id: 67a2b8cb6af73ecd60a2d822e0b2a4af5dcb914db62c32a4a7f3bb3b51463277
---

# prompt explain how AI file get the prompt from .md files and how I can modify AI not the following prompt such that it reads the prompt as one part and

accept image like in the following code and push it to the parts list.

async executeLLM (prompt: string, imagePath?: string): Promise<string> {
try {
// Initialize Gemini AI
const genAI = new GoogleGenerativeAI(this.apiKey);
const model = genAI.getGenerativeModel({
model: "gemini-2.5-flash-lite",
generationConfig: {
maxOutputTokens: 1000,
}
});
const parts: any\[] = \[{ text: prompt }];

```
        if (imagePath) {
        const imageData = fs.readFileSync(imagePath);
        parts.push({
            inlineData: {
            data: imageData.toString("base64"),
            mimeType: "image/png",
            },
        });
        }

        // Execute the LLM
        const result = await model.generateContent(parts);
        const response = await result.response;
        const text = response.text();
        return text;
    } catch (error) {
        console.error('‚ùå Error calling Gemini API:', (error as Error).message);
        throw error;
    }    }
```
